{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a020c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "from tqdm.notebook import tqdm as tn\n",
    "import nltk\n",
    "import regex as re\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = nltk.corpus.stopwords.words('russian')\n",
    "english_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_tokenizer = nltk.WordPunctTokenizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e90335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://spbu.ru/</td>\n",
       "      <td>2023-04-14T00:56:50.6368499Z</td>\n",
       "      <td>Главная | Санкт-Петербургский государствен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://cabinet.spbu.ru/Account/LogOn/</td>\n",
       "      <td>2023-04-14T00:57:02.6226399Z</td>\n",
       "      <td>Вход      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://bb.spbu.ru/</td>\n",
       "      <td>2023-04-14T00:57:02.6225294Z</td>\n",
       "      <td>Blackboard Learn                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://events.spbu.ru/</td>\n",
       "      <td>2023-04-14T00:57:03.8827793Z</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cabinet.spbu.ru/Account/Register/</td>\n",
       "      <td>2023-04-14T00:57:06.6414451Z</td>\n",
       "      <td>Регистраци...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0                             1  \\\n",
       "0                           https://spbu.ru/  2023-04-14T00:56:50.6368499Z   \n",
       "1     https://cabinet.spbu.ru/Account/LogOn/  2023-04-14T00:57:02.6226399Z   \n",
       "2                         http://bb.spbu.ru/  2023-04-14T00:57:02.6225294Z   \n",
       "3                    https://events.spbu.ru/  2023-04-14T00:57:03.8827793Z   \n",
       "4  https://cabinet.spbu.ru/Account/Register/  2023-04-14T00:57:06.6414451Z   \n",
       "\n",
       "                                                   2  \n",
       "0      Главная | Санкт-Петербургский государствен...  \n",
       "1                                      Вход      ...  \n",
       "2    Blackboard Learn                            ...  \n",
       "3                                                ...  \n",
       "4                                      Регистраци...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_spbu = pd.read_csv(r\"C:\\Users\\User\\Downloads\\spbu_content.csv\", header = None)\n",
    "data_spbu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959ac17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://msu.ru/</td>\n",
       "      <td>2023-04-15T16:29:55.1662631Z</td>\n",
       "      <td>\\t\\tМосковский государственный университет име...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://msu.ru/news/rss/</td>\n",
       "      <td>2023-04-15T16:30:13.1464229Z</td>\n",
       "      <td>\\tНовости МГУhttp://www.msu.ruSat, 15 Apr 2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://270.msu.ru/</td>\n",
       "      <td>2023-04-15T16:30:09.1446391Z</td>\n",
       "      <td>270 лет Московскому университету     Указ Пре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://conf.msu.ru/rus/event/8147/</td>\n",
       "      <td>2023-04-15T16:30:09.1695835Z</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://nosh.msu.ru/</td>\n",
       "      <td>2023-04-15T16:30:11.2455821Z</td>\n",
       "      <td>Научно-образовательные школы Московского унив...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0                             1  \\\n",
       "0                      https://msu.ru/  2023-04-15T16:29:55.1662631Z   \n",
       "1             https://msu.ru/news/rss/  2023-04-15T16:30:13.1464229Z   \n",
       "2                   http://270.msu.ru/  2023-04-15T16:30:09.1446391Z   \n",
       "3  https://conf.msu.ru/rus/event/8147/  2023-04-15T16:30:09.1695835Z   \n",
       "4                  http://nosh.msu.ru/  2023-04-15T16:30:11.2455821Z   \n",
       "\n",
       "                                                   2  \n",
       "0  \\t\\tМосковский государственный университет име...  \n",
       "1  \\tНовости МГУhttp://www.msu.ruSat, 15 Apr 2023...  \n",
       "2   270 лет Московскому университету     Указ Пре...  \n",
       "3                                                ...  \n",
       "4   Научно-образовательные школы Московского унив...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_msu = pd.read_csv(r\"C:\\Users\\User\\Downloads\\msu_content.csv\", header = None)\n",
    "data_msu.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6943a498",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7d55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"dctv\"\n",
    "def has_cyrillic(text): # проверяем, слово содержит русские буквы или нет \n",
    "    return bool(re.search('[а-яА-Я]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7115ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"路\"\n",
    "def has_english(text): # проверяем, слово содержит английские буквы или нет \n",
    "    return bool(re.search('[a-zA-z]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcbeda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spbu = data_spbu[~data_spbu[0].str.endswith('.pdf/')] # удаляем строки из датафрейма, которые пдфки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e098d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def lemmatization(data_spbu):\n",
    "    df = data_spbu.copy()\n",
    "    list_errors = list()\n",
    "    for i in tn(data_spbu.index):\n",
    "        if i < 30433:\n",
    "            sub_string = data_spbu.iloc[i, 2]\n",
    "        if type(sub_string) is str:\n",
    "            word_list = nltk.word_tokenize(sub_string.lower()) # делаем маленькие буквы, разбиваем текст на токены (из 3-го столбика по каждой строке)\n",
    "            word_list = [word for word in word_list if (word not in russian_stopwords and not word.isnumeric() and word not in english_stopwords and (has_cyrillic(word) or has_english(word)))] # удаляем слова, которые в англ и русс стоп-словах или если они числовые (строчки)\n",
    "            try:\n",
    "                word_list = [morph.parse(j)[0].normal_form for j in word_list] # нормальная форма токена\n",
    "                df.iloc[i, 2] = ' '.join(word_list) # заменяем 3 столбик на лемматизированный текст\n",
    "            except:\n",
    "                list_errors.append(i) # в лист ошибок добавляем номер строки, в которой ошибка \n",
    "                df.iloc[i, 2] = '' # зануляем строку, в которой ошибка\n",
    "    return df, list_errors \n",
    "df, list_errors = lemmatization(data_spbu) # переменные из ретерна, которые возвращает функция \n",
    "# df.to_csv('df.csv') # сохраняем обработанный датафрейм в новый csv для последующего использования (токенизированный и почищенный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a064507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_errors = [426, # лист с ошибками\n",
    "3306,\n",
    "4132,\n",
    "7316,\n",
    "8177,\n",
    "8209,\n",
    "8277,\n",
    "8354,\n",
    "8500,\n",
    "8525,\n",
    "8851,\n",
    "9725,\n",
    "9726,\n",
    "9784,\n",
    "9829,\n",
    "9857,\n",
    "9957,\n",
    "9994,\n",
    "10082,\n",
    "10430,\n",
    "10431,\n",
    "10432,\n",
    "10966,\n",
    "11017,\n",
    "11025,\n",
    "11045,\n",
    "11215,\n",
    "11306,\n",
    "11533,\n",
    "11691,\n",
    "11784,\n",
    "12063,\n",
    "12214,\n",
    "12273,\n",
    "12526,\n",
    "12528,\n",
    "12760,\n",
    "12769,\n",
    "12884,\n",
    "12927,\n",
    "12974,\n",
    "14278,\n",
    "15082,\n",
    "16247,\n",
    "16267,\n",
    "16316,\n",
    "16360,\n",
    "16600,\n",
    "16803,\n",
    "17497,\n",
    "17772,\n",
    "18650,\n",
    "18690,\n",
    "18817,\n",
    "20048,\n",
    "20664,\n",
    "21126,\n",
    "21710,\n",
    "22305,\n",
    "22794,\n",
    "23144,\n",
    "23278,\n",
    "23613,\n",
    "23720,\n",
    "23766,\n",
    "23838,\n",
    "23911,\n",
    "24235,\n",
    "24485,\n",
    "25062,\n",
    "25117,\n",
    "25512,\n",
    "25775,\n",
    "26357,\n",
    "27083,\n",
    "27179,\n",
    "27583,\n",
    "29401,\n",
    "29573,\n",
    "29743,\n",
    "30433]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b55aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "df = data_spbu.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a875edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# мне нужен словарь, в котором слова - ключи, а значения(которые соответствуют этим ключам - списки)\n",
    "# то есть каждому слову соответствует список ссылок из df.csv, в которых содержится это слово\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd0346f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302be746455647cfa7d9346e1de28e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m                     my_dict[j] \u001b[39m=\u001b[39m [df\u001b[39m.\u001b[39miloc[i][\u001b[39m0\u001b[39m]] \u001b[39m# пыталась тут добавить ключ и значение (то есть ссылку), если их нет в словаре \u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m my_dict\n\u001b[1;32m---> 23\u001b[0m my_dict \u001b[39m=\u001b[39m create_dict(df, list_errors)\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mcreate_dict\u001b[1;34m(df, list_errors)\u001b[0m\n\u001b[0;32m     10\u001b[0m df_size \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]   \n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tn(df\u001b[39m.\u001b[39mindex):  \u001b[39m# цикл, который обрабатывает строки\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m list_errors \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(df\u001b[39m.\u001b[39;49miloc[i][\u001b[39m2\u001b[39m], \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m i \u001b[39m<\u001b[39m df_size:\n\u001b[0;32m     13\u001b[0m         tokens_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m     14\u001b[0m         tokens_list \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[i][\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit() \u001b[39m# если строка не встречается в листе ошибок (то что не получилось обработать на лемматизации)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Work\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Work\\lib\\site-packages\\pandas\\core\\indexing.py:1625\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1624\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1625\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_integer(key, axis)\n\u001b[0;32m   1627\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Work\\lib\\site-packages\\pandas\\core\\indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('df.csv', index_col=0)\n",
    "list_errors = [426, 3306, 4132,7316, 8177, 8209, 8277, 8354, 8500, 8525, 8851, 9725, 9726, 9784, 9829, 9857, 9957, 9994, 10082, 10430, 10431, \n",
    "               10432, 10966, 11017, 11025, 11045, 11215, 11306, 11533, 11691, 11784, 12063, 12214, 12273, 12526, 12528, 12760, 12769, 12884,\n",
    "               12927, 12974, 14278, 15082, 16247, 16267, 16316, 16360, 16600, 16803, 17497, 17772, 18650, 18690, 18817, 20048, 20664, 21126,\n",
    "               21710, 22305, 22794, 23144, 23278, 23613, 23720, 23766, 23838, 23911, 24235, 24485, 25062, 25117, 25512, 25775, 26357, 27083, \n",
    "               27179, 27583, 29401, 29573, 29743, 30433] \n",
    "# list_errors = lemmatization(data_spbu)\n",
    "def create_dict(df, list_errors):\n",
    "    my_dict = {}\n",
    "    df_size = df.shape[0]   \n",
    "    for i in tn(df.index):  # цикл, который обрабатывает строки\n",
    "        if i not in list_errors and isinstance(df.iloc[i][2], str) and i < df_size:\n",
    "            tokens_list = list()\n",
    "            tokens_list = df.iloc[i][2].split() # если строка не встречается в листе ошибок (то что не получилось обработать на лемматизации)\n",
    "            for j in tokens_list: # тут цикл, который обрабатывает токены (он смотрит, есть ли какая-то запись в словаре, соответствующая конкретному слову)\n",
    "                if j in my_dict: # если ключ уже есть, то добавляем в список ссылку\n",
    "                    my_dict[j].append(df.iloc[i][0]) \n",
    "                else:  \n",
    "                    my_dict[j] = [df.iloc[i][0]] # пыталась тут добавить ключ и значение (то есть ссылку), если их нет в словаре \n",
    "\n",
    "    return my_dict\n",
    "\n",
    "my_dict = create_dict(df, list_errors)           \n",
    "            # если запись в словаре есть - идем дальше, если записи в словаре нет - добавляем эту строку в лист для конкретного ключа\n",
    "            # ну либо (если первый раз встречается) создаем лист, в который записывается значение строки для ключа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b84eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # сохраняем словарь в файл \n",
    "with open('result.json', 'w') as fp:\n",
    "    json.dump(my_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97ee40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
